{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Image Classification\n",
    "The following notebook is responsible for demonstrating how one would go about creating and evaluating a model using the two image generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from preprocessing.data_generator import CustomGen\n",
    "from meta.paths import PATH_TO_TRAIN_PAIRS, PATH_TO_TEST_PAIRS\n",
    "from models.prototype import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (100, 100)\n",
    "IMAGE_SHAPE = IMAGE_SIZE + (3,)\n",
    "EPOCHS = 1\n",
    "FIT_AND_SAVE = False\n",
    "BUILD_ON_PREVIOUS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Traing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIT_AND_SAVE: # creates a model from scratch and saves it\n",
    "    train_pairs_df = pd.read_csv(PATH_TO_TRAIN_PAIRS) \n",
    "    train_generator = CustomGen(train_pairs_df,\n",
    "                                shuffle=True, \n",
    "                                batch_size=BATCH_SIZE, \n",
    "                                image_size=IMAGE_SIZE)\n",
    "    if BUILD_ON_PREVIOUS:\n",
    "        model = keras.models.load_model(\"model.h5\")\n",
    "    else:\n",
    "        model = create_model(IMAGE_SHAPE)\n",
    "    checkpoint_filepath = \"model.h5\"\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        save_freq=\"epoch\")\n",
    "\n",
    "    # The model weights (that are considered the best) are loaded into the model.\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    history = model.fit(train_generator, \n",
    "                        epochs=EPOCHS, \n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        callbacks=[model_checkpoint_callback])\n",
    "    model.save(\"model.h5\")\n",
    "else:  # loads previous run\n",
    "    model = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model\n",
    "TODO: Only testing N pairs\n",
    "TODO: Testing images are getting augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, auc\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    pred_classifications = list(map(lambda s: 0 if s < .5 else 1, y_pred))\n",
    "    ap_score = average_precision_score(y_true, y_pred)\n",
    "    a_score = accuracy_score(y_true, pred_classifications)\n",
    "    return ap_score, a_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 validated image filenames belonging to 2 classes.\n",
      "Found 500 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "N_TEST_PAIRS = 500\n",
    "test_pairs = pd.read_csv(PATH_TO_TEST_PAIRS).sample(n=N_TEST_PAIRS)\n",
    "test_generator = CustomGen(test_pairs, shuffle=True, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, use_plain_generator=True)\n",
    "predictions = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \t 0.5\n",
      "Test AP: \t 0.2990978426754176\n"
     ]
    }
   ],
   "source": [
    "y_true = test_pairs[\"class_label\"]\n",
    "ap_score, a_score = get_metrics(y_true, predictions)\n",
    "\n",
    "print(\"Test Accuracy: \\t\", a_score)\n",
    "print(\"Test AP: \\t\", ap_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy: Random Chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \t 0.544\n",
      "Test AP: \t 0.35767373284425996\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "x = random.random()\n",
    "random_scores = [random.random() for i in range(len(y_true))]\n",
    "ap_score, a_score = get_metrics(y_true, random_scores)\n",
    "print(\"Test Accuracy: \\t\", a_score)\n",
    "print(\"Test AP: \\t\", ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
